{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Exploratory Data Analysis (Hands on)</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"eda.jpg\"  width = \"50%\"  height = \"50%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Exploratory Data Analysis refers to the critical process of performing initial investigations on data so as to discover patterns, to spot anomalies, to test hypothesis and to check assumptions with the help of summary statistics and graphical representations.\n",
    "</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Working with data</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This involves the operation mechanism that revolves around data, This includes data acquisition,discovery,structuring,cleaning and exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Setting up my workspace path</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Importing the os library is to interact with the with the files and directories</b><br>\n",
    "\n",
    "<b>Import os</b> : this is the library/module that helps to interact with the operating system of the computer , in terms of working path etc.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>os.chdir() </b> : This function helps to change the working directory to the specified folder<br>\n",
    "\n",
    "<b>os.getcwd()</b> : This function helps to get the working path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Spicywords'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('C:\\\\Users\\\\Spicywords')\n",
    "#C:\\\\Users\\\\Spicywords\\\\Documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Spicywords'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Libraries to Implement</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Pandas</b>: This is  a library which is responsible for the acquisition, manipution and  transformation of data .\n",
    "\n",
    "<b>Numpy</b> : This library is responsible for fast numerical calculations. Eg matrixes , vectors, arrays.\n",
    "\n",
    "<b>MatplotLib</b> : This library is responsible for visualization during the EDA stage.\n",
    "It functions in the specialty of creating plots, charts and graphs.\n",
    "\n",
    "<b>Seaborn</b> : it provides a high- level interface for drawing attractive and informative statistical graphics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Guidelines that will be used to acheive a good Exploratory data analysis workflow </h3><br>\n",
    "<h3>1.Data Access / Acquisition</h3>\n",
    "<h3>2.Data Preparation</h3>\n",
    "<h3>3.Exploratory Data Analysis</h3>\n",
    "<h3>4.Reporting </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Data Acquisition</h3></b>\n",
    "<h3>The gathering of source data for data entry into the computer.</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h4>Different data sources with Pandas</h4></b><br>\n",
    "\n",
    "<b>Csv</b> : Comma Seperated Values<br>\n",
    "\n",
    "<b>Xlsx</b>: A file with the .xlsxÂ is a Microsoft Excel Open XML Spreadsheet (XLSX) file created by Microsoft Excel.<br>\n",
    "\n",
    "<b>Sql</b> : Structured Query Language<br>\n",
    "\n",
    "<b>Json</b> : JavaScript \tObject Notation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h4>Acquiring data from a csv file</h4></b>\n",
    "<h2>read_csv()</h2>\n",
    "<h4>This is a function that is used to read in csv files</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"real_estate_price_size.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h4>Acquiring data from an excel file</h4></b><br>\n",
    "<h2>read_excel()</h2>\n",
    "<h4>This is a function that is used to read in excel files</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"orders and return of supermarket.xlsx\" , index_col = 0 ,header = 0 , sheet_name = 0)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Acquiring data from SQL</h3></b>\n",
    "<b><h4>The example of the Database used is Mysql DBMS(Database Management System)</h4></b><br>\n",
    "\n",
    "connection /interaction with the database is easy using the sql magics<br>\n",
    "create connections using this format %sql mysql://username:password@host/dbname<br>\n",
    "before that we have to install the library that will intialise the sql magics<br>\n",
    "<h4> Run pip install ipython-sql</h4>\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Before we can start using sql magics, we have to  call this function for permission</h4>\n",
    "<h3>load_ext sql</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>sql alchemy format for connecting to the database</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %sql mysql://spicywords:Harbeedeymee_123@localhost/Hrdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Querying the database with the sql Magic</h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from student_academic_performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>Converting my database into table for easy reading </h3></b><br>\n",
    "<h4>importing the sqlalchemy library</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>create an engine from the sqlalchemy library that does the conversion</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql://spicywords:Harbeedeymee_123@localhost/hrdb\",encoding='latin1', echo = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>read_sql() : this is use to read/acquire data in sql format</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('select * from student_academic_performance', engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>.Read_html()<h5><br> Read in the content from a .html file. This is generalized, reading in all body text</h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#web scrape the current covid 19  cases\n",
    "r = requests.get('https://covid19.ncdc.gov.ng')\n",
    "d = pd.read_html(r.text , header = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loop to get the dataframe  \n",
    "for y in d:\n",
    "    p = pd.DataFrame(y)\n",
    "    print(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'http://nerdc.org.ng/eCurriculum/CurriculumView.aspx?SubjectId=23&SubEducationLevelId=1'\n",
    "response = requests.get(url)\n",
    "print(response.status_code)\n",
    "soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "table = soup.find('table')\n",
    "tr = table.findAll(['tr','th'])[0:7]\n",
    "csvFile = open(\"Primary 1 General Mathematics3.csv\",'wt',newline='', encoding='utf-8')\n",
    "writer = csv.writer(csvFile)  \n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(\"Primary 1 General Mathematics3.csv\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab work for this chapter\n",
    "1. Change the working directory of your workspace using the OS() (function)<br>\n",
    "2. Read a sample csv file into the jupyter Environment<br>\n",
    "3. Connect the jupyter enviroment to a database and query out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Preprocessing </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data preprocessing  refers to the Preparation of data directly after accessing it from a data source. This involves the  process of cleaning, restructuring and enriching the raw data available into a more usable format.<h3><br>\n",
    "\n",
    "<b>Steps in data Preprocessing</b>\n",
    "\n",
    "<b>Discovering</b><br>\n",
    "<b>Structuring</b><br>\n",
    "<b>Cleaning</b>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Discovering</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Acquisition</h3>\n",
    "<h3>read_excel()</h3>\n",
    "This function will help us get the data into the environment for excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"orders and return of supermarket.xlsx\" , index_col = 0 ,header = 0 , sheet_name = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Head Function</h3><br> This function helps to get first five rows at default, but we can specify the number of rows we want to get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tail Function</h3><br>\n",
    "This function will help to get the last five rows at default but we can specify the number we want to get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Checking the data types using .dtypes()</h3><br>\n",
    "This function will help you know the type of data we are working with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Shape of the data(in terms of columns and Rows)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>.shape()</h3><br>\n",
    "This function will help us get the shape of the data in terms of the rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>.columns()</h3><br>\n",
    "This function will help you get the column names of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Statistical Description using .description()</h3><br>\n",
    "This function will give you statiscal decription of the data we are working with ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Cleaning </h2><br>\n",
    "<h3>Data cleaning is the process of preparing data for analysis by removing or modifying data that is incorrect, incomplete, irrelevant, duplicated, or improperly formatted.<br><br>This data is usually not necessary or helpful when it comes to analyzing data because it may hinder the process or provide inaccurate results.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Converting my columns to UpperCase using .columns.str.upper()</h3><br>\n",
    "This will help us to convert our columns from lower case to upper case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Renaming using  .rename()</h3><br>\n",
    "This function will help us to rename a data into a new one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {\"CUSTOMER SEGMENT\": \"CUSTOMER\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Checking for missing data using is.null()</h3><br>\n",
    "This function will help us to check if there is a na value and it will return a boolean values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>getting a more definite answer for the missing values using .isnull().any()</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>getting a word answer for the missing value using the .isnull().any().any()</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Getting the sum of the missing values with the isnull().sum()</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Replacing the null values with mean , zero values using .fillna()</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the mean of the column with a missing value . we will use the <b>mean()</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PRODUCT BASE MARGIN\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_mean = df.fillna(df[\"PRODUCT BASE MARGIN\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_mean[\"PRODUCT BASE MARGIN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> we have to check for the null values just to be sure we dont have any missing values again  using .isnull().sum()</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_mean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dropping missing values using the dropna()</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_mean = df_with_mean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_mean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_mean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>checking for outliers</h3><br>\n",
    "outlier is an observation of data that does not fit the rest of the data. It is sometimes called an extreme value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_mean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Hands on using various library for visualization</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Common type of Plots using matplotlib & Seaborn Libraries</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Barchat </h3>\n",
    "<h5>A bar chart is a way of summarizing a set of categorical data</h5><br>\n",
    "1. Horizontal Barchat\n",
    "2. Vertical Barchat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>plt : this is the  shortname for the pyplot we called from the python library<br>\n",
    ".barh(): this function is used to render a horizontal barchat<br>\n",
    ".bar() : this function is used to render a vertical barchart<br>\n",
    ".figure() : this function is used to increase the size of the chart in terms of width and height<br>\n",
    ".title () : this function is used to give title to charts<br>\n",
    ".xlabel() : this function is used to give label to the x-axis<br>\n",
    ".ylabel() : this function is used to give label to the y axis</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,6))\n",
    "plt.barh(df[\"REGION\"],df[\"UNIT PRICE\"])\n",
    "plt.title(\"PRODUCT PRICES VIA REGION \")\n",
    "plt.xlabel(\"Region\")\n",
    "plt.ylabel(\"Unit Price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,6))\n",
    "plt.bar(df[\"REGION\"],df[\"UNIT PRICE\"])\n",
    "plt.title(\"PRODUCT PRICES VIA REGION \")\n",
    "plt.xlabel(\"Region\")\n",
    "plt.ylabel(\"Unit Price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ScatterPlot</h3>,<br>\n",
    "<h3>A scatter plot is a type of plot that shows the data as a collection of points. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df[\"UNIT PRICE\"], df[\"DISCOUNT\"], alpha=0.8)\n",
    "plt.title('')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Line Graph </h3><br>\n",
    "A line graph is a type of chart used to show information that changes over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using the Seaborn library to plot a Line graph</h3><br>\n",
    "sns : this is the short form for the seaborn library that will be called for intialization<br>\n",
    ".lineplot(): this function visualizes the plot out<br>\n",
    "df[\"ORDER DATE\"]: x-axis parameter<br>\n",
    "df[\"SALES\"]: y-axis parameter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lineplot using the seaborn library\n",
    "plt.figure(figsize=(20,7))\n",
    "ax = sns.lineplot(df[\"ORDER DATE\"] , df[\"SALES\"])\n",
    "ax.set(xlabel = \"Order Date\" , ylabel = \"Sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using the seaborn library with the .distplot()</h3>\n",
    "<h4>This helps us to check the distribution of our dataset.</h4><br>\n",
    "sns : this is the short form for the seaborn library that will be called for intialization<br>\n",
    ".distplot(): this function visualizes the plot out the distribution plot<br>\n",
    "df[\"DISCOUNT\"]: x-axis parameter<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring in the seaborn library\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(df_with_mean[\"DISCOUNT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_with_mean[\"UNIT PRICE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_with_mean[\"SHIPPING COST\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_with_mean[\"PROFIT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_with_mean[\"SALES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_with_mean[\"QUANTITY ORDERED NEW\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Adjust the outliers using the Quantile()</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = df_with_mean[\"DISCOUNT\"].quantile(0.99)\n",
    "df_with_mean1 = df_with_mean[df_with_mean[\"DISCOUNT\"] < q]\n",
    "df_with_mean1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_with_mean1[\"DISCOUNT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = df_with_mean[\"UNIT PRICE\"].quantile(0.40)\n",
    "df_with_mean2 = df_with_mean1[df_with_mean1[\"UNIT PRICE\"]<q]\n",
    "df_with_mean2.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_with_mean2[\"UNIT PRICE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = df_with_mean[\"SHIPPING COST\"].quantile(0.60)\n",
    "df_with_mean3 = df_with_mean2[df_with_mean2[\"SHIPPING COST\"]<q]\n",
    "df_with_mean3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_with_mean3[\"SHIPPING COST\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = df_with_mean3[\"PROFIT\"].quantile(0.99)\n",
    "df_with_mean4 = df_with_mean3[df_with_mean3[\"PROFIT\"]<q]\n",
    "df_with_mean4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_with_mean4[\"PROFIT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = df_with_mean[\"SALES\"].quantile(0.30)\n",
    "df_with_mean5 = df_with_mean4[df_with_mean4[\"SALES\"]<q]\n",
    "df_with_mean5.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_with_mean5[\"SALES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = df_with_mean5[\"QUANTITY ORDERED NEW\"].quantile(0.99)\n",
    "df_with_mean6 = df_with_mean5[df_with_mean5[\"QUANTITY ORDERED NEW\"]<q]\n",
    "df_with_mean6.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_with_mean6[\"QUANTITY ORDERED NEW\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reseting the index using the .reset_index()</h3><br>\n",
    " reset_index() is a method to reset index of a Dataframe to a new data by erasing the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_with_mean6.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> .Loc() :<h5>The loc property is used to access a group of rows and columns by label(s) or a boolean array.</h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.loc[0:10 , [\"DISCOUNT\",\"REGION\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> .iLoc() :<h5>The iloc is used for integer-location based indexing / selection by position. : </h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.iloc[0:5,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>.Sort_values() <h5>sorts a data frame in Ascending or Descending order of passed Column.</h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[\"SHIPPING COST\"].sort_values(ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>.sort_index()<h5>function sorts objects by labels along the given axis.</h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[\"UNIT PRICE\"].sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>.rank()<h5>Compute numerical data ranks (1 through n) along axis..</h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[\"UNIT PRICE_RANK\"] = df_cleaned[\"UNIT PRICE\"].rank(ascending = True).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.sort_values(by = \"UNIT PRICE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>.Pivot_table()<h5>aggregates a table of data by one or more keys, arranging the data in a rectangle with some of the group keys along the rows and some along the columns into a two-dimensional table that provides a multidimensional summarization of the data.</h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_cleaned.pivot_table(index = \"UNIT PRICE\" ,values =\"SHIPPING COST\" ).sort_values(by = 'SHIPPING COST',ascending = True)\n",
    "\n",
    "df_pivot[\"SHIPPING RANK\"] = df_pivot.rank(ascending = True)\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    ".Groupby()\n",
    "<h5>  \n",
    "groupby operation involves one of the following operations on the original object.  \n",
    "<br>\n",
    "    \n",
    "    \n",
    "Splitting the Object\n",
    "\n",
    "Applying a function\n",
    "\n",
    "Combining the results\n",
    "</h5>\n",
    "\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is mostly used by the categorical variables\n",
    "df_grop_shipmode = df_cleaned.groupby([\"CUSTOMER SEGMENT\",\"PRODUCT CATEGORY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grop_shipmode.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grop_shipmode.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grop_shipmode[\"UNIT PRICE\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grop_shipmode.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grop_shipmode.agg({\"UNIT PRICE\":[\"sum\",\"mean\"] , \"SALES\" : \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grop_shipmode.agg([\"sum\",\"mean\",\"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iteration through the group by\n",
    "df_group_by_customer_sub = pd.DataFrame(columns = df_cleaned.columns)\n",
    "df_group_by_customer_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer_sub ,data in df_grop_shipmode:\n",
    "    highest_sales_cat = data.nlargest(1,\"PROFIT\")\n",
    "    df = df.append(highest_sales_cat)\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities = df_cleaned.groupby(\"CITY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city,data in df_cities:\n",
    "    city_with_the_highest_profit = data.nlargest(1, \"PROFIT\")\n",
    "    df = df.append(city_with_the_highest_profit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Concat():<h5>Concatenate pandas objects along a particular axis with optional set logic along the other axes.</h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\"orders and return of supermarket.xlsx\" , index_col = 0 ,header = 0 , sheet_name = 0)\n",
    "df2 = pd.read_excel(\"orders and return of supermarket.xlsx\" , index_col = 0 ,header = 0 , sheet_name = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df1),len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.concat([df1,df2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.concat([df1,df2] , keys = [\"week1\",\"week2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>.Merge()<h5>pandas has full-featured, high performance in-memory join operations idiomatically very similar to relational databases like SQL. </h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_excel(\"orders and return of supermarket.xlsx\" , index_col = 0 ,header = 0 , sheet_name = 0)\n",
    "new_df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_1 = pd.read_excel(\"orders and return of supermarket.xlsx\" , index_col = 0 ,header = 0 , sheet_name = 1)\n",
    "new_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(new_df,new_df_1 , how = \"left\" , left_on = \"Customer ID\" , right_on = \"Order ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>.apply()<h5>Apply a function along an axis of the DataFrame.</h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>.map():<h5>Used for substituting each value in a Series with another value, that may be derived from a function, a dict or a Series.</h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[\"PRODUCT CATEGORY\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[\"PRODUCT CATEGORY\"].map({'Office Supplies' : 0 ,'Furniture' :1 , 'Technology' : 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>.get_dummies()<br> <h5>Convert categorical variable into dummy/indicator variables.</h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_created = pd.get_dummies(df_cleaned['PRODUCT CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>.f_oneway():<h5>This helps us to get the correllation between different groups of a categorical variable </h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[\"PRODUCT CATEGORY\"] = df_cleaned[\"PRODUCT CATEGORY\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[\"PRODUCT SUB-CATEGORY\"] = df_cleaned[\"PRODUCT SUB-CATEGORY\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>.corr():<h5>This helps us to get the association between variables </h5></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check the correllation between\n",
    "correlate = df_cleaned.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corre = correlate.index\n",
    "plt.figure(figsize = (14 ,10))\n",
    "\n",
    "\n",
    "sns.heatmap(df_cleaned[corre].corr() , annot = True , cmap = 'RdYlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convert from sales to the log of the sales using the np.log()</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the sales column to the a new one\n",
    "log_sales = np.log(df_cleaned[\"SALES\"])\n",
    "df_cleaned[\"LOG SALES\"] = log_sales\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Checking out Relationship between Variables</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Linearity</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_cleaned[\"SALES\"] , df_cleaned[\"UNIT PRICE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_cleaned[\"SALES\"] , df_cleaned[\"DISCOUNT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_cleaned[\"LOG SALES\"],df_cleaned[\"PROFIT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_cleaned[\"LOG SALES\"],df_cleaned[\"UNIT PRICE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Collinearity</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = df_cleaned[['UNIT PRICE' , 'DISCOUNT' , 'SHIPPING COST' ,'LOG SALES']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif['vif'] = [variance_inflation_factor(variables.values,i)for i in range(variables.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif[\"features\"] = variables.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exploring via Visualization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using seaborn\n",
    "sns.catplot(x =\"PROFIT\" , y = \"PRODUCT SUB-CATEGORY\" ,data = df_cleaned ,kind = \"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x =\"PRODUCT CATEGORY\" , y = \"SALES\" ,data = df_cleaned,kind= \"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x =\"REGION\" , y =\"SALES\" , data = df_cleaned ,kind = \"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x =\"PRODUCT CATEGORY\" , y = \"PROFIT\" ,data = df_cleaned,kind= \"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x =\"DISCOUNT\" , y = \"SALES\" ,data = df_cleaned,kind= \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Exporting Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting  data into different sources\n",
    "\n",
    "#df_cleaned.to_csv('data_cleaned.csv')\n",
    "\n",
    "#df_cleaned.to_json('data_cleaned.json')\n",
    "\n",
    "#df_cleaned.to_sql('order' ,con = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
